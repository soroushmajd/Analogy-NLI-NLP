{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "pip install dadmatools "
      ],
      "metadata": {
        "id": "SEi7csrsj1GV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ff495e73-7ff9-4054-cecf-932b584ae03c"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting dadmatools\n",
            "  Downloading dadmatools-1.5.2-py3-none-any.whl (862 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m862.6/862.6 KB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: gensim>=3.6.0 in /usr/local/lib/python3.8/dist-packages (from dadmatools) (3.6.0)\n",
            "Collecting conllu\n",
            "  Downloading conllu-4.5.2-py2.py3-none-any.whl (16 kB)\n",
            "Collecting pytorch-transformers>=1.1.0\n",
            "  Downloading pytorch_transformers-1.2.0-py3-none-any.whl (176 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m176.4/176.4 KB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting py7zr>=0.17.2\n",
            "  Downloading py7zr-0.20.2-py3-none-any.whl (65 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.8/65.8 KB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h5py>=3.3.0\n",
            "  Downloading h5py-3.8.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.7/4.7 MB\u001b[0m \u001b[31m63.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting segtok>=1.5.7\n",
            "  Downloading segtok-1.5.11-py3-none-any.whl (24 kB)\n",
            "Collecting NERDA\n",
            "  Downloading NERDA-1.0.0-py3-none-any.whl (23 kB)\n",
            "Requirement already satisfied: spacy>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from dadmatools) (3.4.4)\n",
            "Collecting Deprecated==1.2.6\n",
            "  Downloading Deprecated-1.2.6-py2.py3-none-any.whl (8.1 kB)\n",
            "Requirement already satisfied: folium>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from dadmatools) (0.12.1.post1)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.8/dist-packages (from dadmatools) (3.7)\n",
            "Collecting sklearn>=0.0\n",
            "  Downloading sklearn-0.0.post1.tar.gz (3.6 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting bpemb>=0.3.3\n",
            "  Downloading bpemb-0.3.4-py3-none-any.whl (19 kB)\n",
            "Requirement already satisfied: torch>=1.7.1 in /usr/local/lib/python3.8/dist-packages (from dadmatools) (1.13.1+cu116)\n",
            "Collecting transformers>=4.9.1\n",
            "  Downloading transformers-4.26.0-py3-none-any.whl (6.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m63.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tabulate>=0.8.6 in /usr/local/lib/python3.8/dist-packages (from dadmatools) (0.8.10)\n",
            "Collecting hyperopt>=0.2.5\n",
            "  Downloading hyperopt-0.2.7-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: gdown>=4.3.1 in /usr/local/lib/python3.8/dist-packages (from dadmatools) (4.4.0)\n",
            "Collecting supar==1.1.2\n",
            "  Downloading supar-1.1.2-py3-none-any.whl (87 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.9/87.9 KB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pyconll>=3.1.0\n",
            "  Downloading pyconll-3.1.0-py3-none-any.whl (26 kB)\n",
            "Collecting tf-estimator-nightly==2.8.0.dev2021122109\n",
            "  Downloading tf_estimator_nightly-2.8.0.dev2021122109-py2.py3-none-any.whl (462 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m462.5/462.5 KB\u001b[0m \u001b[31m21.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting html2text\n",
            "  Downloading html2text-2020.1.16-py3-none-any.whl (32 kB)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.8/dist-packages (from Deprecated==1.2.6->dadmatools) (1.14.1)\n",
            "Collecting stanza\n",
            "  Downloading stanza-1.4.2-py3-none-any.whl (691 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m691.3/691.3 KB\u001b[0m \u001b[31m43.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: dill in /usr/local/lib/python3.8/dist-packages (from supar==1.1.2->dadmatools) (0.3.6)\n",
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.97-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m60.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from bpemb>=0.3.3->dadmatools) (1.21.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from bpemb>=0.3.3->dadmatools) (2.25.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from bpemb>=0.3.3->dadmatools) (4.64.1)\n",
            "Requirement already satisfied: branca>=0.3.0 in /usr/local/lib/python3.8/dist-packages (from folium>=0.2.1->dadmatools) (0.6.0)\n",
            "Requirement already satisfied: jinja2>=2.9 in /usr/local/lib/python3.8/dist-packages (from folium>=0.2.1->dadmatools) (2.11.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from gdown>=4.3.1->dadmatools) (3.9.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.8/dist-packages (from gdown>=4.3.1->dadmatools) (4.6.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from gdown>=4.3.1->dadmatools) (1.15.0)\n",
            "Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.8/dist-packages (from gensim>=3.6.0->dadmatools) (6.3.0)\n",
            "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.8/dist-packages (from gensim>=3.6.0->dadmatools) (1.7.3)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.8/dist-packages (from hyperopt>=0.2.5->dadmatools) (0.16.0)\n",
            "Collecting py4j\n",
            "  Downloading py4j-0.10.9.7-py2.py3-none-any.whl (200 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m200.5/200.5 KB\u001b[0m \u001b[31m23.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: cloudpickle in /usr/local/lib/python3.8/dist-packages (from hyperopt>=0.2.5->dadmatools) (2.2.1)\n",
            "Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.8/dist-packages (from hyperopt>=0.2.5->dadmatools) (3.0)\n",
            "Collecting pyzstd>=0.14.4\n",
            "  Downloading pyzstd-0.15.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (378 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m379.0/379.0 KB\u001b[0m \u001b[31m36.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting inflate64>=0.3.1\n",
            "  Downloading inflate64-0.3.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (94 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.5/94.5 KB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pybcj>=0.6.0\n",
            "  Downloading pybcj-1.0.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (50 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.8/50.8 KB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting texttable\n",
            "  Downloading texttable-1.6.7-py2.py3-none-any.whl (10 kB)\n",
            "Collecting brotli>=1.0.9\n",
            "  Downloading Brotli-1.0.9-cp38-cp38-manylinux1_x86_64.whl (357 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m357.2/357.2 KB\u001b[0m \u001b[31m34.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting multivolumefile>=0.2.3\n",
            "  Downloading multivolumefile-0.2.3-py3-none-any.whl (17 kB)\n",
            "Collecting pyppmd<1.1.0,>=0.18.1\n",
            "  Downloading pyppmd-1.0.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (139 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.7/139.7 KB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pycryptodomex>=3.6.6\n",
            "  Downloading pycryptodomex-3.17-cp35-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m85.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: psutil in /usr/local/lib/python3.8/dist-packages (from py7zr>=0.17.2->dadmatools) (5.4.8)\n",
            "Collecting boto3\n",
            "  Downloading boto3-1.26.67-py3-none-any.whl (132 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.7/132.7 KB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: regex in /usr/local/lib/python3.8/dist-packages (from pytorch-transformers>=1.1.0->dadmatools) (2022.6.2)\n",
            "Collecting sacremoses\n",
            "  Downloading sacremoses-0.0.53.tar.gz (880 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m880.6/880.6 KB\u001b[0m \u001b[31m59.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.0 in /usr/local/lib/python3.8/dist-packages (from spacy>=3.0.0->dadmatools) (8.1.7)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from spacy>=3.0.0->dadmatools) (57.4.0)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.8/dist-packages (from spacy>=3.0.0->dadmatools) (1.0.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from spacy>=3.0.0->dadmatools) (23.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /usr/local/lib/python3.8/dist-packages (from spacy>=3.0.0->dadmatools) (1.10.4)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in /usr/local/lib/python3.8/dist-packages (from spacy>=3.0.0->dadmatools) (0.10.1)\n",
            "Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.8/dist-packages (from spacy>=3.0.0->dadmatools) (0.10.1)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from spacy>=3.0.0->dadmatools) (1.0.4)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from spacy>=3.0.0->dadmatools) (2.0.7)\n",
            "Requirement already satisfied: typer<0.8.0,>=0.3.0 in /usr/local/lib/python3.8/dist-packages (from spacy>=3.0.0->dadmatools) (0.7.0)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.10 in /usr/local/lib/python3.8/dist-packages (from spacy>=3.0.0->dadmatools) (3.0.12)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.8/dist-packages (from spacy>=3.0.0->dadmatools) (2.0.8)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.8/dist-packages (from spacy>=3.0.0->dadmatools) (2.4.5)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.8/dist-packages (from spacy>=3.0.0->dadmatools) (3.3.0)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from spacy>=3.0.0->dadmatools) (3.0.8)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch>=1.7.1->dadmatools) (4.4.0)\n",
            "Collecting huggingface-hub<1.0,>=0.11.0\n",
            "  Downloading huggingface_hub-0.12.0-py3-none-any.whl (190 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m190.3/190.3 KB\u001b[0m \u001b[31m22.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
            "  Downloading tokenizers-0.13.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m101.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers>=4.9.1->dadmatools) (6.0)\n",
            "Collecting progressbar\n",
            "  Downloading progressbar-2.5.tar.gz (10 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (from NERDA->dadmatools) (1.3.5)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.8/dist-packages (from nltk->dadmatools) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.8/dist-packages (from nltk->dadmatools) (1.2.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.8/dist-packages (from jinja2>=2.9->folium>=0.2.1->dadmatools) (2.0.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->bpemb>=0.3.3->dadmatools) (2022.12.7)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->bpemb>=0.3.3->dadmatools) (2.10)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->bpemb>=0.3.3->dadmatools) (1.24.3)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->bpemb>=0.3.3->dadmatools) (4.0.0)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.8/dist-packages (from thinc<8.2.0,>=8.1.0->spacy>=3.0.0->dadmatools) (0.7.9)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.8/dist-packages (from thinc<8.2.0,>=8.1.0->spacy>=3.0.0->dadmatools) (0.0.4)\n",
            "Collecting s3transfer<0.7.0,>=0.6.0\n",
            "  Downloading s3transfer-0.6.0-py3-none-any.whl (79 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.6/79.6 KB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting jmespath<2.0.0,>=0.7.1\n",
            "  Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Collecting botocore<1.30.0,>=1.29.67\n",
            "  Downloading botocore-1.29.67-py3-none-any.whl (10.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.4/10.4 MB\u001b[0m \u001b[31m106.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas->NERDA->dadmatools) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas->NERDA->dadmatools) (2022.7.1)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.8/dist-packages (from requests->bpemb>=0.3.3->dadmatools) (1.7.1)\n",
            "Collecting emoji\n",
            "  Downloading emoji-2.2.0.tar.gz (240 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m240.9/240.9 KB\u001b[0m \u001b[31m26.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.8/dist-packages (from stanza->supar==1.1.2->dadmatools) (3.19.6)\n",
            "Collecting urllib3<1.27,>=1.21.1\n",
            "  Downloading urllib3-1.26.14-py2.py3-none-any.whl (140 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m140.6/140.6 KB\u001b[0m \u001b[31m18.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: sklearn, progressbar, sacremoses, emoji\n",
            "  Building wheel for sklearn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sklearn: filename=sklearn-0.0.post1-py3-none-any.whl size=2344 sha256=da5f86b3f6f63ddb5066ed07d08a2a6a79f24b5a12439d8d573f6d6ae330312a\n",
            "  Stored in directory: /root/.cache/pip/wheels/14/25/f7/1cc0956978ae479e75140219088deb7a36f60459df242b1a72\n",
            "  Building wheel for progressbar (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for progressbar: filename=progressbar-2.5-py3-none-any.whl size=12081 sha256=43ef4b4a75100963a7a4ffa5a0fb3cc82f9bc668231ec6a38cab8e227615dfb1\n",
            "  Stored in directory: /root/.cache/pip/wheels/2c/67/ed/d84123843c937d7e7f5ba88a270d11036473144143355e2747\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.53-py3-none-any.whl size=895260 sha256=e43b872acbc7650149527540423f50a232070d6484bdaeeea2f8b061f94df1c1\n",
            "  Stored in directory: /root/.cache/pip/wheels/82/ab/9b/c15899bf659ba74f623ac776e861cf2eb8608c1825ddec66a4\n",
            "  Building wheel for emoji (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for emoji: filename=emoji-2.2.0-py3-none-any.whl size=234926 sha256=01a09c6065377537035fc643884eab40d525da3b87d33faedc4eafcfa4b9cf9b\n",
            "  Stored in directory: /root/.cache/pip/wheels/86/62/9e/a6b27a681abcde69970dbc0326ff51955f3beac72f15696984\n",
            "Successfully built sklearn progressbar sacremoses emoji\n",
            "Installing collected packages: tokenizers, tf-estimator-nightly, texttable, sklearn, sentencepiece, py4j, progressbar, brotli, urllib3, segtok, sacremoses, pyzstd, pyppmd, pycryptodomex, pyconll, pybcj, multivolumefile, jmespath, inflate64, html2text, h5py, emoji, Deprecated, conllu, py7zr, hyperopt, botocore, stanza, s3transfer, huggingface-hub, bpemb, transformers, boto3, supar, pytorch-transformers, NERDA, dadmatools\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "  Attempting uninstall: h5py\n",
            "    Found existing installation: h5py 3.1.0\n",
            "    Uninstalling h5py-3.1.0:\n",
            "      Successfully uninstalled h5py-3.1.0\n",
            "  Attempting uninstall: hyperopt\n",
            "    Found existing installation: hyperopt 0.1.2\n",
            "    Uninstalling hyperopt-0.1.2:\n",
            "      Successfully uninstalled hyperopt-0.1.2\n",
            "Successfully installed Deprecated-1.2.6 NERDA-1.0.0 boto3-1.26.67 botocore-1.29.67 bpemb-0.3.4 brotli-1.0.9 conllu-4.5.2 dadmatools-1.5.2 emoji-2.2.0 h5py-3.8.0 html2text-2020.1.16 huggingface-hub-0.12.0 hyperopt-0.2.7 inflate64-0.3.1 jmespath-1.0.1 multivolumefile-0.2.3 progressbar-2.5 py4j-0.10.9.7 py7zr-0.20.2 pybcj-1.0.1 pyconll-3.1.0 pycryptodomex-3.17 pyppmd-1.0.0 pytorch-transformers-1.2.0 pyzstd-0.15.3 s3transfer-0.6.0 sacremoses-0.0.53 segtok-1.5.11 sentencepiece-0.1.97 sklearn-0.0.post1 stanza-1.4.2 supar-1.1.2 texttable-1.6.7 tf-estimator-nightly-2.8.0.dev2021122109 tokenizers-0.13.2 transformers-4.26.0 urllib3-1.26.14\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import dadmatools"
      ],
      "metadata": {
        "id": "ubUfHzoe3qaW"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install fasttext\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "7J29yRfQlUaA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9646b6c3-7b08-4c4d-ee6e-9379923284f8"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting fasttext\n",
            "  Downloading fasttext-0.9.2.tar.gz (68 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m68.8/68.8 KB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pybind11>=2.2\n",
            "  Using cached pybind11-2.10.3-py3-none-any.whl (222 kB)\n",
            "Requirement already satisfied: setuptools>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from fasttext) (57.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from fasttext) (1.21.6)\n",
            "Building wheels for collected packages: fasttext\n",
            "  Building wheel for fasttext (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fasttext: filename=fasttext-0.9.2-cp38-cp38-linux_x86_64.whl size=4400095 sha256=e997b30a7e9666a1d48d5ccd7cf77f760e66b08a958ecb8e05982d15754a63a2\n",
            "  Stored in directory: /root/.cache/pip/wheels/93/61/2a/c54711a91c418ba06ba195b1d78ff24fcaad8592f2a694ac94\n",
            "Successfully built fasttext\n",
            "Installing collected packages: pybind11, fasttext\n",
            "Successfully installed fasttext-0.9.2 pybind11-2.10.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install utility"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ZbH_GS7o2zR",
        "outputId": "9b92f2f9-f68b-4312-bfa4-e8a339e0c041"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting utility\n",
            "  Downloading utility-1.0.tar.gz (3.1 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: utility\n",
            "  Building wheel for utility (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for utility: filename=utility-1.0-py3-none-any.whl size=3833 sha256=3fac4d251adc8d7bf78de0091b356b325f111fc26fe9317feef011d57e37fcaa\n",
            "  Stored in directory: /root/.cache/pip/wheels/01/88/f4/d0334bff483f781913d511756d750e37a1dc44e79e38893d41\n",
            "Successfully built utility\n",
            "Installing collected packages: utility\n",
            "Successfully installed utility-1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv(\"/content/Test_file.txt\", engine='python',encoding='utf-8', error_bad_lines=False)\n",
        "\n",
        "df.columns = [\"cat\", \"first\", \"second\", \"third\",\"fourth\"]\n",
        "\n",
        "print(\"The size of the analogy test set is : {}\".format(len(df)))\n",
        "print(df.head())\n",
        "\n"
      ],
      "metadata": {
        "id": "H8tf1YwbpBWm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1b764234-d16e-4b19-d15a-d791f4ea8c8f"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The size of the analogy test set is : 129\n",
            "    cat     first   second      third   fourth\n",
            "0  city     اهواز  خوزستان        قشم  هرمزگان\n",
            "1  city     شیراز     فارس     دامغان    سمنان\n",
            "2  city       رشت    گیلان  اسلام‌شهر    تهران\n",
            "3  city  بندرعباس  هرمزگان      ملارد    تهران\n",
            "4  city      اراک    مرکزی     مریوان  کردستان\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/IPython/core/interactiveshell.py:3326: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version.\n",
            "\n",
            "\n",
            "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "fasttext"
      ],
      "metadata": {
        "id": "MTxzQC64RA0a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import dadmatools\n",
        "from dadmatools.embeddings import get_embedding, get_all_embeddings_info, get_embedding_info\n",
        "embedding_info = get_embedding_info('fasttext-commoncrawl-vec')\n",
        "fasttext_embedding = get_embedding('fasttext-commoncrawl-vec')\n",
        "vocab = fasttext_embedding.get_vocab()\n"
      ],
      "metadata": {
        "id": "3VcAiqo5kapZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bdfc2d0d-884a-4a99-f33d-3af38a5100bb"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cc.fa.300.vec.gz: 100%|██████████| 1.17G/1.17G [00:44<00:00, 28.6MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "def find_cosine_similarity(vector1, vector2):\n",
        "    dot = np.dot(vector1,vector2)\n",
        "    norm1 = np.sqrt(np.sum(vector1**2))\n",
        "    norm2 = np.sqrt(np.sum(vector2**2))\n",
        "    cosine_sim = dot/(norm1)/norm2\n",
        "    \n",
        "    return cosine_sim"
      ],
      "metadata": {
        "id": "GbhB2wh_meLg"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def find_word_analogy(a, b, c, embedding):\n",
        "    # Get the word embeddings\n",
        "    emb_a, emb_b, emb_c = fasttext_embedding[a], fasttext_embedding[b], fasttext_embedding[c]\n",
        "    \n",
        "    # Get the nearest 100000 words to word_c\n",
        "    nearest = fasttext_embedding.top_nearest(c, 100)\n",
        "    word_list = [word[0] for word in nearest]\n",
        "    max_similarity = -100000\n",
        "    chosen_word = None\n",
        "\n",
        "    # Search for word_d in the word vector set\n",
        "    for word in word_list:\n",
        "        # Skip input words\n",
        "        if word in [a, b, c]:\n",
        "            continue\n",
        "\n",
        "        # Compute cosine similarity between vectors\n",
        "        sim = find_cosine_similarity(emb_b - emb_a, fasttext_embedding[word] - emb_c)\n",
        "        \n",
        "        # Update chosen word if similarity is higher\n",
        "        if sim > max_similarity:\n",
        "            max_similarity = sim\n",
        "            chosen_word = word\n",
        "\n",
        "    return chosen_word    "
      ],
      "metadata": {
        "id": "tlRBlFzTsuXX"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "fasttext accuracy"
      ],
      "metadata": {
        "id": "-ZalI-5g45kF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y= df[df[\"cat\"]==\"city\"]"
      ],
      "metadata": {
        "id": "7kA7mqWIqYl9"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        },
        "id": "VbLeAzrgqZ2V",
        "outputId": "5e097cc1-90a6-4908-97e4-90e7bedea10c"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    cat      first   second      third   fourth\n",
              "0  city      اهواز  خوزستان        قشم  هرمزگان\n",
              "1  city      شیراز     فارس     دامغان    سمنان\n",
              "2  city        رشت    گیلان  اسلام‌شهر    تهران\n",
              "3  city   بندرعباس  هرمزگان      ملارد    تهران\n",
              "4  city       اراک    مرکزی     مریوان  کردستان\n",
              "5  city  اسلام‌شهر    تهران       جهرم     فارس\n",
              "6  city      سنندج  کردستان     آبادان  خوزستان\n",
              "7  city      گرگان   گلستان        قشم  هرمزگان\n",
              "8  city      ملارد    تهران       جهرم     فارس"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a684d756-274f-4b50-b483-f45708ea7f93\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>cat</th>\n",
              "      <th>first</th>\n",
              "      <th>second</th>\n",
              "      <th>third</th>\n",
              "      <th>fourth</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>city</td>\n",
              "      <td>اهواز</td>\n",
              "      <td>خوزستان</td>\n",
              "      <td>قشم</td>\n",
              "      <td>هرمزگان</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>city</td>\n",
              "      <td>شیراز</td>\n",
              "      <td>فارس</td>\n",
              "      <td>دامغان</td>\n",
              "      <td>سمنان</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>city</td>\n",
              "      <td>رشت</td>\n",
              "      <td>گیلان</td>\n",
              "      <td>اسلام‌شهر</td>\n",
              "      <td>تهران</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>city</td>\n",
              "      <td>بندرعباس</td>\n",
              "      <td>هرمزگان</td>\n",
              "      <td>ملارد</td>\n",
              "      <td>تهران</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>city</td>\n",
              "      <td>اراک</td>\n",
              "      <td>مرکزی</td>\n",
              "      <td>مریوان</td>\n",
              "      <td>کردستان</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>city</td>\n",
              "      <td>اسلام‌شهر</td>\n",
              "      <td>تهران</td>\n",
              "      <td>جهرم</td>\n",
              "      <td>فارس</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>city</td>\n",
              "      <td>سنندج</td>\n",
              "      <td>کردستان</td>\n",
              "      <td>آبادان</td>\n",
              "      <td>خوزستان</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>city</td>\n",
              "      <td>گرگان</td>\n",
              "      <td>گلستان</td>\n",
              "      <td>قشم</td>\n",
              "      <td>هرمزگان</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>city</td>\n",
              "      <td>ملارد</td>\n",
              "      <td>تهران</td>\n",
              "      <td>جهرم</td>\n",
              "      <td>فارس</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a684d756-274f-4b50-b483-f45708ea7f93')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a684d756-274f-4b50-b483-f45708ea7f93 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a684d756-274f-4b50-b483-f45708ea7f93');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y= df[df[\"cat\"]==\"city\"]\n",
        "first = y[\"first\"]\n",
        "second = y[\"second\"]\n",
        "third = y[\"third\"]\n",
        "fourth = y[\"fourth\"]\n",
        "accuracy = 0\n",
        "for i in range (9):\n",
        "    print(i)\n",
        "    inputs = [(first[i], second[i], third[i])]\n",
        "\n",
        "    for input in inputs:\n",
        "        word4 = find_word_analogy(*input, fasttext_embedding)\n",
        "        print (input)\n",
        "        print (word4)\n",
        "        if (word4==fourth[i]):\n",
        "            accuracy = accuracy + 1\n",
        "                   \n",
        "num = y[\"cat\"].count()      \n",
        "print(accuracy/num)      \n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mPj3l_9SU2TM",
        "outputId": "9ba3fd30-fc5f-4103-8369-31fc973e683a"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "('اهواز', 'خوزستان', 'قشم')\n",
            "دارآژند\n",
            "1\n",
            "('شیراز', 'فارس', 'دامغان')\n",
            "سمنان\n",
            "2\n",
            "('رشت', 'گیلان', 'اسلام\\u200cشهر')\n",
            "اسلام‌شه\n",
            "3\n",
            "('بندرعباس', 'هرمزگان', 'ملارد')\n",
            "ملار\n",
            "4\n",
            "('اراک', 'مرکزی', 'مریوان')\n",
            "خاوومیرآباد\n",
            "5\n",
            "('اسلام\\u200cشهر', 'تهران', 'جهرم')\n",
            "لار\n",
            "6\n",
            "('سنندج', 'کردستان', 'آبادان')\n",
            "خوزستان\n",
            "7\n",
            "('گرگان', 'گلستان', 'قشم')\n",
            "جزیره\n",
            "8\n",
            "('ملارد', 'تهران', 'جهرم')\n",
            "بوشهر\n",
            "0.2222222222222222\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y= df[df[\"cat\"]==\"capital\"]\n",
        "first = y[\"first\"]\n",
        "second = y[\"second\"]\n",
        "third = y[\"third\"]\n",
        "fourth = y[\"fourth\"]\n",
        "accuracy = 0\n",
        "for i in range (9,19):\n",
        "    print(i)\n",
        "    inputs = [(first[i], second[i], third[i])]\n",
        "\n",
        "    for input in inputs:\n",
        "        if(input[0] in vocab and input[1] in vocab and input[2] in vocab):\n",
        "            word4 = find_word_analogy(*input, fasttext_embedding)\n",
        "            print (input)\n",
        "            print (word4)\n",
        "            if (word4==fourth[i]):\n",
        "                accuracy = accuracy + 1\n",
        "                \n",
        "num = y[\"cat\"].count()      \n",
        "print(accuracy/num)      \n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9d405168-fa13-4d41-ba67-fe7505eb3199",
        "id": "c4eJZzoGYnYi"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9\n",
            "('روسیه', 'مسکو', 'هلند')\n",
            "آمستردام\n",
            "10\n",
            "('کره\\u200cجنوبی', 'سئول', 'آمریکا')\n",
            "متحده\n",
            "11\n",
            "('ایران', 'تهران', 'اسپانیا')\n",
            "بارسلون\n",
            "12\n",
            "('ایران', 'تهران', 'افغانستان')\n",
            "اقغانستان\n",
            "13\n",
            "('بریتانیا', 'لندن', 'فنلاند')\n",
            "هلسینکی\n",
            "14\n",
            "('تایلند', 'بانکوک', 'چین')\n",
            "پکن\n",
            "15\n",
            "('مصر', 'قاهره', 'چین')\n",
            "شانگهای\n",
            "16\n",
            "('اندونزی', 'جاکارتا', 'اتریش')\n",
            "اینسبورگ\n",
            "17\n",
            "('عراق', 'بغداد', 'بلغارستان')\n",
            "بلغارستان98سایر\n",
            "18\n",
            "('آلمان', 'برلین', 'اسپانیا')\n",
            "مادرید\n",
            "0.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y= df[df[\"cat\"]==\"currency\"]\n",
        "first = y[\"first\"]\n",
        "second = y[\"second\"]\n",
        "third = y[\"third\"]\n",
        "fourth = y[\"fourth\"]\n",
        "accuracy = 0\n",
        "for i in range (19,29):\n",
        "    print(i)\n",
        "    inputs = [(first[i], second[i], third[i])]\n",
        "\n",
        "    for input in inputs:\n",
        "        if(input[0] in vocab and input[1] in vocab and input[2] in vocab):\n",
        "            word4 = find_word_analogy(*input, fasttext_embedding)\n",
        "            print (input)\n",
        "            print (word4)\n",
        "            if (word4==fourth[i]):\n",
        "                accuracy = accuracy + 1\n",
        "                   \n",
        "num = y[\"cat\"].count()      \n",
        "print(accuracy/num)      \n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jths3p-RYqds",
        "outputId": "2b28b1a3-f7a8-4257-8a65-abf6258396db"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "19\n",
            "('سوئد', 'کرون', 'امارات')\n",
            "امارات۸,۸۳۳\n",
            "20\n",
            "('سوئیس', 'فرانک', 'تاجیکستان')\n",
            "دشتی‌بت\n",
            "21\n",
            "('رومانی', 'لئو', 'بریتانیا')\n",
            "بریتانیایی\n",
            "22\n",
            "('ترکیه', 'لیره', 'افغانستان')\n",
            "افغانتسان\n",
            "23\n",
            "('چین', 'یوان', 'عراق')\n",
            "درعراق\n",
            "24\n",
            "('اروپا', 'یورو', 'ایران')\n",
            "ایرانی\n",
            "25\n",
            "('اروپا', 'یورو', 'هند')\n",
            "کرالای\n",
            "26\n",
            "('ژاپن', 'ین', 'اروپا')\n",
            "اورپا\n",
            "27\n",
            "('سوئیس', 'فرانک', 'کنیا')\n",
            "کنیایی\n",
            "28\n",
            "('عربستان', 'ریال', 'امارات')\n",
            "امارات۸,۸۳۳\n",
            "0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y= df[df[\"cat\"]==\"family\"]\n",
        "first = y[\"first\"]\n",
        "second = y[\"second\"]\n",
        "third = y[\"third\"]\n",
        "fourth = y[\"fourth\"]\n",
        "accuracy = 0\n",
        "for i in range (29,39):\n",
        "    print(i)\n",
        "    inputs = [(first[i], second[i], third[i])]\n",
        "\n",
        "    for input in inputs:\n",
        "        if(input[0] in vocab and input[1] in vocab and input[2] in vocab):\n",
        "            word4 = find_word_analogy(*input, fasttext_embedding)\n",
        "            print (input)\n",
        "            print (word4)\n",
        "            if (word4==fourth[i]):\n",
        "                accuracy = accuracy + 1\n",
        "                \n",
        "num = y[\"cat\"].count()      \n",
        "print(accuracy/num)      \n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xgcgUafBYqj9",
        "outputId": "d3aa0cc8-2a6c-43a5-ffe2-843c097fa3bd"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "29\n",
            "('برادر', 'خواهر', 'پدر')\n",
            "مادر\n",
            "30\n",
            "('برادرها', 'خواهرها', 'شوهر')\n",
            "شوهري\n",
            "31\n",
            "('پدربزرگ', 'مادربزرگ', 'برادر')\n",
            "خواهرن\n",
            "32\n",
            "('بابابزرگ', 'مامان\\u200cبزرگ', 'داماد')\n",
            "دامادِ\n",
            "33\n",
            "('داماد', 'عروس', 'برادرها')\n",
            "خواهرها\n",
            "34\n",
            "('شوهر', 'عیال', 'دایی')\n",
            "دائی\n",
            "35\n",
            "('شاه', 'ملکه', 'برادر')\n",
            "خواهرهای\n",
            "36\n",
            "('آقا', 'خانم', 'آقاجون')\n",
            "آقاجونی\n",
            "37\n",
            "('عمو', 'عمه', 'پدربزرگ')\n",
            "مادربزرگ\n",
            "38\n",
            "('دایی', 'خاله', 'پسردایی')\n",
            "دخترعمه\n",
            "0.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y= df[df[\"cat\"]==\"gram_thirdperson\"]\n",
        "first = y[\"first\"]\n",
        "second = y[\"second\"]\n",
        "third = y[\"third\"]\n",
        "fourth = y[\"fourth\"]\n",
        "accuracy = 0\n",
        "for i in range (39,49):\n",
        "    print(i)\n",
        "    inputs = [(first[i], second[i], third[i])]\n",
        "\n",
        "    for input in inputs:\n",
        "        if(input[0] in vocab and input[1] in vocab and input[2] in vocab):\n",
        "            word4 = find_word_analogy(*input, fasttext_embedding)\n",
        "            print (input)\n",
        "            print (word4)\n",
        "            if (word4==fourth[i]):\n",
        "                accuracy = accuracy + 1\n",
        "                \n",
        "num = y[\"cat\"].count()      \n",
        "print(accuracy/num)      \n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1mX0b1ULYq4M",
        "outputId": "fb30d132-1b8e-4468-9afa-4ce1f89e2296"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "39\n",
            "('برید', 'بریدند', 'رقصید')\n",
            "رقصند\n",
            "40\n",
            "('پرید', 'پریدند', 'آمد')\n",
            "آمدند\n",
            "41\n",
            "('تازید', 'تازیدند', 'گفت')\n",
            "افزود\n",
            "42\n",
            "('شد', 'شدند', 'بوسید')\n",
            "بوسیدند\n",
            "43\n",
            "('کرد', 'کردند', 'آمد')\n",
            "آمدند\n",
            "44\n",
            "('گفت', 'گفتند', 'رقصید')\n",
            "رقصند\n",
            "45\n",
            "('توانست', 'توانستند', 'یافت')\n",
            "یافتند\n",
            "46\n",
            "('پخت', 'پختند', 'نامید')\n",
            "نامیدند\n",
            "47\n",
            "('رسید', 'رسیدند', 'شد')\n",
            "شدد\n",
            "48\n",
            "('خواست', 'خواستند', 'آمد')\n",
            "آمدند\n",
            "0.6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y= df[df[\"cat\"]==\"gram_past\"]\n",
        "first = y[\"first\"]\n",
        "second = y[\"second\"]\n",
        "third = y[\"third\"]\n",
        "fourth = y[\"fourth\"]\n",
        "accuracy = 0\n",
        "for i in range (49,59):\n",
        "    print(i)\n",
        "    inputs = [(first[i], second[i], third[i])]\n",
        "\n",
        "    for input in inputs:\n",
        "        if(input[0] in vocab and input[1] in vocab and input[2] in vocab):\n",
        "            word4 = find_word_analogy(*input, fasttext_embedding)\n",
        "            print (input)\n",
        "            print (word4)\n",
        "            if (word4==fourth[i]):\n",
        "                accuracy = accuracy + 1\n",
        "             \n",
        "num = y[\"cat\"].count()   \n",
        "print(accuracy/num)   "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y-RhFSqQYq88",
        "outputId": "4127fe23-a788-4df6-e906-49e5f94a604c"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "49\n",
            "('بریدن', 'برید', 'دمیدن')\n",
            "دمید\n",
            "50\n",
            "('تازیدن', 'تاخت', 'دادن')\n",
            "آوردن\n",
            "51\n",
            "('شدن', 'شد', 'نگریستن')\n",
            "نگریستند\n",
            "52\n",
            "('گفتن', 'گفت', 'رقصیدن')\n",
            "رقصید\n",
            "53\n",
            "('گفتن', 'گفت', 'خواستن')\n",
            "خواست\n",
            "54\n",
            "('توانستن', 'توانست', 'رسیدن')\n",
            "رسیدن‌اش\n",
            "55\n",
            "('رفتن', 'رفت', 'زدن')\n",
            "بزند\n",
            "56\n",
            "('رفتن', 'رفت', 'افزودن')\n",
            "سبد\n",
            "57\n",
            "('گرفتن', 'گرفت', 'توانستن')\n",
            "ميتونستن\n",
            "58\n",
            "('خواستن', 'خواست', 'فرمودن')\n",
            "فرمودند\n",
            "0.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y= df[df[\"cat\"]==\"gram_firstperson\"]\n",
        "first = y[\"first\"]\n",
        "second = y[\"second\"]\n",
        "third = y[\"third\"]\n",
        "fourth = y[\"fourth\"]\n",
        "accuracy = 0\n",
        "for i in range (59,69):\n",
        "    print(i)\n",
        "    inputs = [(first[i], second[i], third[i])]\n",
        "\n",
        "    for input in inputs:\n",
        "        if(input[0] in vocab and input[1] in vocab and input[2] in vocab):\n",
        "            word4 = find_word_analogy(*input, fasttext_embedding)\n",
        "            print (input)\n",
        "            print (word4)\n",
        "            if (word4==fourth[i]):\n",
        "                accuracy = accuracy + 1\n",
        "             \n",
        "num = y[\"cat\"].count()   \n",
        "print(accuracy/num)     \n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "si3GEyXhYrCV",
        "outputId": "1fef4a91-eff4-4dea-d774-2a2dab77ec67"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "59\n",
            "('دادم', 'دادیم', 'یافتم')\n",
            "نمی‌یافتم\n",
            "60\n",
            "('زدم', 'زدیم', 'نامیدم')\n",
            "نامیدیم\n",
            "61\n",
            "('نوشتم', 'نوشتیم', 'گفتم')\n",
            "گفتیم\n",
            "62\n",
            "('دانستم', 'دانستیم', 'بلعیدم')\n",
            "بلعیدیم\n",
            "63\n",
            "('گردیدم', 'گردیدیم', 'یافتم')\n",
            "می‌یافتم\n",
            "64\n",
            "('گردیدم', 'گردیدیم', 'بوسیدم')\n",
            "بوسیدیم\n",
            "65\n",
            "('گذاشتم', 'گذاشتیم', 'کردم')\n",
            "کردم.باز\n",
            "66\n",
            "('گذاشتم', 'گذاشتیم', 'ماندم')\n",
            "ماندما\n",
            "67\n",
            "('نگریستم', 'نگریستیم', 'رقصیدم')\n",
            "رقصیدیم\n",
            "68\n",
            "('یافتم', 'یافتیم', 'دمیدم')\n",
            "دمیدیم\n",
            "0.6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y= df[df[\"cat\"]==\"gram_adj2adv\"]\n",
        "first = y[\"first\"]\n",
        "second = y[\"second\"]\n",
        "third = y[\"third\"]\n",
        "fourth = y[\"fourth\"]\n",
        "accuracy = 0\n",
        "for i in range (69,79):\n",
        "    print(i)\n",
        "    inputs = [(first[i], second[i], third[i])]\n",
        "\n",
        "    for input in inputs:\n",
        "        if(input[0] in vocab and input[1] in vocab and input[2] in vocab):\n",
        "            word4 = find_word_analogy(*input, fasttext_embedding)\n",
        "            print (input)\n",
        "            print (word4)\n",
        "            if (word4==fourth[i]):\n",
        "                accuracy = accuracy + 1\n",
        "             \n",
        "num = y[\"cat\"].count()   \n",
        "print(accuracy/num)     \n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DP08up8nYrHJ",
        "outputId": "da3080c2-04a7-4946-fbb5-a10b4ac79d84"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "69\n",
            "('مجدد', 'مجددا', 'مخصوص')\n",
            "مخصوصش\n",
            "70\n",
            "('عمده', 'عمدتا', 'صمیمی')\n",
            "صميمي\n",
            "71\n",
            "('دقیق', 'دقیقا', 'عادل')\n",
            "عادلي\n",
            "72\n",
            "('غالب', 'غالبا', 'جدا')\n",
            "جداشود\n",
            "73\n",
            "('متناظر', 'متناظرا', 'قبل')\n",
            "قبلاولین\n",
            "74\n",
            "('متاسف', 'متاسفانه', 'قبل')\n",
            "قبلاز\n",
            "75\n",
            "('خوشبخت', 'خوشبختانه', 'مجدد')\n",
            "چندباره\n",
            "76\n",
            "('صمیمی', 'صمیمانه', 'صادق')\n",
            "صادقبه\n",
            "77\n",
            "('آزاد', 'آزادانه', 'متاسف')\n",
            "متاسف‌ام\n",
            "78\n",
            "('آگاه', 'آگاهانه', 'سرسخت')\n",
            "سرسخت‌ترین\n",
            "0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y= df[df[\"cat\"]==\"gram_noun2adv\"]\n",
        "first = y[\"first\"]\n",
        "second = y[\"second\"]\n",
        "third = y[\"third\"]\n",
        "fourth = y[\"fourth\"]\n",
        "accuracy = 0\n",
        "for i in range (79,89):\n",
        "    print(i)\n",
        "    inputs = [(first[i], second[i], third[i])]\n",
        "\n",
        "    for input in inputs:\n",
        "        if(input[0] in vocab and input[1] in vocab and input[2] in vocab):\n",
        "            word4 = find_word_analogy(*input, fasttext_embedding)\n",
        "            print (input)\n",
        "            print (word4)\n",
        "            if (word4==fourth[i]):\n",
        "                accuracy = accuracy + 1\n",
        "             \n",
        "num = y[\"cat\"].count()   \n",
        "print(accuracy/num)     \n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-9C_mEhvYrR8",
        "outputId": "e9717945-77c7-4394-a71d-301c88c1d045"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "79\n",
            "('اتفاق', 'اتفاقا', 'شب')\n",
            "تاصبح\n",
            "80\n",
            "('حتم', 'حتما', 'اساس')\n",
            "حسب\n",
            "81\n",
            "('اصل', 'اصلا', 'انسان')\n",
            "آدمی\n",
            "82\n",
            "('عمل', 'عملا', 'اجبار')\n",
            "اجبارا\n",
            "83\n",
            "('اجبار', 'اجبارا', 'کودک')\n",
            "کودکاگر\n",
            "84\n",
            "('دائم', 'دائما', 'اتفاق')\n",
            "اتفاقاتی\n",
            "85\n",
            "('طبع', 'طبعا', 'سوم')\n",
            "چهام\n",
            "86\n",
            "('نسبت', 'نسبتا', 'اصل')\n",
            "اساسی\n",
            "87\n",
            "('اصول', 'اصولا', 'دوم')\n",
            "ودوم\n",
            "88\n",
            "('اساس', 'اساسا', 'نسبت')\n",
            "کمتری\n",
            "0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y= df[df[\"cat\"]==\"gram_antonym\"]\n",
        "first = y[\"first\"]\n",
        "second = y[\"second\"]\n",
        "third = y[\"third\"]\n",
        "fourth = y[\"fourth\"]\n",
        "accuracy = 0\n",
        "for i in range (89,99):\n",
        "    print(i)\n",
        "    inputs = [(first[i], second[i], third[i])]\n",
        "\n",
        "    for input in inputs:\n",
        "        if(input[0] in vocab and input[1] in vocab and input[2] in vocab):\n",
        "            word4 = find_word_analogy(*input, fasttext_embedding)\n",
        "            print (input)\n",
        "            print (word4)\n",
        "            if (word4==fourth[i]):\n",
        "                accuracy = accuracy + 1\n",
        "          \n",
        "num = y[\"cat\"].count()   \n",
        "print(accuracy/num)     "
      ],
      "metadata": {
        "id": "_il1Y_gUYrXj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4425be34-69a0-4a7e-cf4c-2c3cba472243"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "89\n",
            "('خشنود', 'ناخشنود', 'موفق')\n",
            "ناموفق\n",
            "90\n",
            "('درست', 'نادرست', 'پخته')\n",
            "نپخته‌ای\n",
            "91\n",
            "('مناسب', 'نامناسب', 'همزمان')\n",
            "ناهمزمانی\n",
            "92\n",
            "('مربوط', 'نامربوط', 'منسجم')\n",
            "هدفدار\n",
            "93\n",
            "('بینا', 'نابینا', 'درست')\n",
            "است.درست\n",
            "94\n",
            "('کارآمد', 'ناکارآمد', 'هنجار')\n",
            "نابهنجار\n",
            "95\n",
            "('راضی', 'ناراضی', 'مطلوب')\n",
            "نامطلوب\n",
            "96\n",
            "('مطلوب', 'نامطلوب', 'مناسب')\n",
            "نامناسب\n",
            "97\n",
            "('پیدا', 'ناپیدا', 'متعارف')\n",
            "غير\n",
            "98\n",
            "('مساعد', 'نامساعد', 'درست')\n",
            "اشتباه\n",
            "0.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y= df[df[\"cat\"]==\"gram_comparative\"]\n",
        "first = y[\"first\"]\n",
        "second = y[\"second\"]\n",
        "third = y[\"third\"]\n",
        "fourth = y[\"fourth\"]\n",
        "accuracy = 0\n",
        "for i in range (99,109):\n",
        "    print(i)\n",
        "    inputs = [(first[i], second[i], third[i])]\n",
        "\n",
        "    for input in inputs:\n",
        "        if(input[0] in vocab and input[1] in vocab and input[2] in vocab):\n",
        "            word4 = find_word_analogy(*input, fasttext_embedding)\n",
        "            print (input)\n",
        "            print (word4)\n",
        "            if (word4==fourth[i]):\n",
        "                accuracy = accuracy + 1\n",
        "          \n",
        "num = y[\"cat\"].count()   \n",
        "print(accuracy/num)    "
      ],
      "metadata": {
        "id": "kdcy-L64Yrc-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b4b4160b-d1db-4096-9209-fd682c19d37b"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "99\n",
            "('سریع', 'سریعتر', 'بلند')\n",
            "بلندتر\n",
            "100\n",
            "('بزرگ', 'بزرگتر', 'شدید')\n",
            "شدیدتر\n",
            "101\n",
            "('مهم', 'مهمتر', 'بارز')\n",
            "بارزتیوپ\n",
            "102\n",
            "('به', 'بهتر', 'سرد')\n",
            "خنک\n",
            "103\n",
            "('واضح', 'واضحتر', 'بیش')\n",
            "یکهزار\n",
            "104\n",
            "('کم', 'کمتر', 'بد')\n",
            "بدی\n",
            "105\n",
            "('بالا', 'بالاتر', 'به')\n",
            "از\n",
            "106\n",
            "('معروف', 'معروفتر', 'مشهور')\n",
            "مشهورهای\n",
            "107\n",
            "('بلند', 'بلندتر', 'نزدیک')\n",
            "نزدیک‌تر\n",
            "108\n",
            "('بد', 'بدتر', 'مهم')\n",
            "حیاتیست\n",
            "0.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y= df[df[\"cat\"]==\"gram_nationality\"]\n",
        "first = y[\"first\"]\n",
        "second = y[\"second\"]\n",
        "third = y[\"third\"]\n",
        "fourth = y[\"fourth\"]\n",
        "accuracy = 0\n",
        "for i in range (109,118):\n",
        "    print(i)\n",
        "    inputs = [(first[i], second[i], third[i])]\n",
        "\n",
        "    for input in inputs:\n",
        "        if(input[0] in vocab and input[1] in vocab and input[2] in vocab):\n",
        "            word4 = find_word_analogy(*input, fasttext_embedding)\n",
        "            print (input)\n",
        "            print (word4)\n",
        "            if (word4==fourth[i]):\n",
        "                accuracy = accuracy + 1\n",
        "          \n",
        "num = y[\"cat\"].count()   \n",
        "print(accuracy/num)    "
      ],
      "metadata": {
        "id": "hbteZqBcim2m",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c3e6dd4e-c897-418e-dda7-843d2bfa926d"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "109\n",
            "('اتریش', 'اتریشی', 'اسپانیا')\n",
            "اسپانیایی\n",
            "110\n",
            "('سوئد', 'سوئدی', 'فنلاند')\n",
            "فنلاندی\n",
            "111\n",
            "('بحرین', 'بحرینی', 'عراق')\n",
            "عراقی\n",
            "112\n",
            "('کویت', 'کویتی', 'سوریه')\n",
            "سوریهدو\n",
            "113\n",
            "('مصر', 'مصری', 'کرواسی')\n",
            "کرواتی\n",
            "114\n",
            "('مصر', 'مصری', 'فرانسه')\n",
            "فرانسوی\n",
            "115\n",
            "('برزیل', 'برزیلی', 'آمریکا')\n",
            "آمریکایی\n",
            "116\n",
            "('برزیل', 'برزیلی', 'انگلستان')\n",
            "انگلستانی\n",
            "117\n",
            "('روسیه', 'روسی', 'یونان')\n",
            "یونانی\n",
            "0.6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y= df[df[\"cat\"]==\"gram_plural\"]\n",
        "first = y[\"first\"]\n",
        "second = y[\"second\"]\n",
        "third = y[\"third\"]\n",
        "fourth = y[\"fourth\"]\n",
        "accuracy = 0\n",
        "for i in range (119,128):\n",
        "    print(i)\n",
        "    inputs = [(first[i], second[i], third[i])]\n",
        "\n",
        "    for input in inputs:\n",
        "        if(input[0] in vocab and input[1] in vocab and input[2] in vocab):\n",
        "            word4 = find_word_analogy(*input, fasttext_embedding)\n",
        "            print (input)\n",
        "            print (word4)\n",
        "            if (word4==fourth[i]):\n",
        "                accuracy = accuracy + 1\n",
        "          \n",
        "num = y[\"cat\"].count()   \n",
        "print(accuracy/num)    "
      ],
      "metadata": {
        "id": "3QCVzHlmituW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b3748559-db4e-4b33-d504-c93dd1683a73"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "119\n",
            "('تالیف', 'تالیفات', 'مخلوق')\n",
            "بالذات\n",
            "120\n",
            "('اثر', 'اثرات', 'ارزش')\n",
            "ارزشتر\n",
            "121\n",
            "('انقلابی', 'انقلابیون', 'مورد')\n",
            "مورد‌\n",
            "122\n",
            "('حواری', 'حواریون', 'مورد')\n",
            "مدنظر\n",
            "123\n",
            "('مسئول', 'مسئولین', 'آزاده')\n",
            "بازدیدآزاده\n",
            "124\n",
            "('مسافر', 'مسافرین', 'طلا')\n",
            "جواهرات\n",
            "125\n",
            "('مجرم', 'مجرمین', 'شورا')\n",
            "کارگروه\n",
            "126\n",
            "('انسان', 'انسانها', 'پرنده')\n",
            "پرندههای\n",
            "127\n",
            "('ارز', 'ارزها', 'بیگانه')\n",
            "بیگانه‌تر\n",
            "0.0\n"
          ]
        }
      ]
    }
  ]
}