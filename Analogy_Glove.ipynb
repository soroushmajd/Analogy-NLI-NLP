{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "TRAgqwO8e0a0"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchtext.vocab as vocab"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install dadmatools "
      ],
      "metadata": {
        "id": "SEi7csrsj1GV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e5eec72a-2160-4fb7-9047-b39b079c81a5"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting dadmatools\n",
            "  Downloading dadmatools-1.5.2-py3-none-any.whl (862 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m862.6/862.6 KB\u001b[0m \u001b[31m19.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: gdown>=4.3.1 in /usr/local/lib/python3.8/dist-packages (from dadmatools) (4.4.0)\n",
            "Collecting conllu\n",
            "  Downloading conllu-4.5.2-py2.py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: folium>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from dadmatools) (0.12.1.post1)\n",
            "Collecting sklearn>=0.0\n",
            "  Downloading sklearn-0.0.post1.tar.gz (3.6 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting transformers>=4.9.1\n",
            "  Downloading transformers-4.26.0-py3-none-any.whl (6.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m94.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pytorch-transformers>=1.1.0\n",
            "  Downloading pytorch_transformers-1.2.0-py3-none-any.whl (176 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m176.4/176.4 KB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting bpemb>=0.3.3\n",
            "  Downloading bpemb-0.3.4-py3-none-any.whl (19 kB)\n",
            "Collecting html2text\n",
            "  Downloading html2text-2020.1.16-py3-none-any.whl (32 kB)\n",
            "Collecting tf-estimator-nightly==2.8.0.dev2021122109\n",
            "  Downloading tf_estimator_nightly-2.8.0.dev2021122109-py2.py3-none-any.whl (462 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m462.5/462.5 KB\u001b[0m \u001b[31m22.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: gensim>=3.6.0 in /usr/local/lib/python3.8/dist-packages (from dadmatools) (3.6.0)\n",
            "Requirement already satisfied: torch>=1.7.1 in /usr/local/lib/python3.8/dist-packages (from dadmatools) (1.13.1+cu116)\n",
            "Collecting pyconll>=3.1.0\n",
            "  Downloading pyconll-3.1.0-py3-none-any.whl (26 kB)\n",
            "Collecting supar==1.1.2\n",
            "  Downloading supar-1.1.2-py3-none-any.whl (87 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.9/87.9 KB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting py7zr>=0.17.2\n",
            "  Downloading py7zr-0.20.2-py3-none-any.whl (65 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.8/65.8 KB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from dadmatools) (3.4.4)\n",
            "Collecting segtok>=1.5.7\n",
            "  Downloading segtok-1.5.11-py3-none-any.whl (24 kB)\n",
            "Collecting NERDA\n",
            "  Downloading NERDA-1.0.0-py3-none-any.whl (23 kB)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.8/dist-packages (from dadmatools) (3.7)\n",
            "Collecting h5py>=3.3.0\n",
            "  Downloading h5py-3.8.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.7/4.7 MB\u001b[0m \u001b[31m85.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting Deprecated==1.2.6\n",
            "  Downloading Deprecated-1.2.6-py2.py3-none-any.whl (8.1 kB)\n",
            "Requirement already satisfied: tabulate>=0.8.6 in /usr/local/lib/python3.8/dist-packages (from dadmatools) (0.8.10)\n",
            "Collecting hyperopt>=0.2.5\n",
            "  Downloading hyperopt-0.2.7-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m36.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.8/dist-packages (from Deprecated==1.2.6->dadmatools) (1.14.1)\n",
            "Collecting stanza\n",
            "  Downloading stanza-1.4.2-py3-none-any.whl (691 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m691.3/691.3 KB\u001b[0m \u001b[31m32.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: dill in /usr/local/lib/python3.8/dist-packages (from supar==1.1.2->dadmatools) (0.3.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from bpemb>=0.3.3->dadmatools) (2.25.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from bpemb>=0.3.3->dadmatools) (4.64.1)\n",
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.97-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m58.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from bpemb>=0.3.3->dadmatools) (1.21.6)\n",
            "Requirement already satisfied: branca>=0.3.0 in /usr/local/lib/python3.8/dist-packages (from folium>=0.2.1->dadmatools) (0.6.0)\n",
            "Requirement already satisfied: jinja2>=2.9 in /usr/local/lib/python3.8/dist-packages (from folium>=0.2.1->dadmatools) (2.11.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from gdown>=4.3.1->dadmatools) (1.15.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from gdown>=4.3.1->dadmatools) (3.9.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.8/dist-packages (from gdown>=4.3.1->dadmatools) (4.6.3)\n",
            "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.8/dist-packages (from gensim>=3.6.0->dadmatools) (1.7.3)\n",
            "Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.8/dist-packages (from gensim>=3.6.0->dadmatools) (6.3.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.8/dist-packages (from hyperopt>=0.2.5->dadmatools) (0.16.0)\n",
            "Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.8/dist-packages (from hyperopt>=0.2.5->dadmatools) (3.0)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.8/dist-packages (from hyperopt>=0.2.5->dadmatools) (2.2.1)\n",
            "Collecting py4j\n",
            "  Downloading py4j-0.10.9.7-py2.py3-none-any.whl (200 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m200.5/200.5 KB\u001b[0m \u001b[31m23.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pycryptodomex>=3.6.6\n",
            "  Downloading pycryptodomex-3.17-cp35-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m89.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: psutil in /usr/local/lib/python3.8/dist-packages (from py7zr>=0.17.2->dadmatools) (5.4.8)\n",
            "Collecting pybcj>=0.6.0\n",
            "  Downloading pybcj-1.0.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (50 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.8/50.8 KB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting texttable\n",
            "  Downloading texttable-1.6.7-py2.py3-none-any.whl (10 kB)\n",
            "Collecting brotli>=1.0.9\n",
            "  Downloading Brotli-1.0.9-cp38-cp38-manylinux1_x86_64.whl (357 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m357.2/357.2 KB\u001b[0m \u001b[31m31.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting inflate64>=0.3.1\n",
            "  Downloading inflate64-0.3.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (94 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.5/94.5 KB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pyzstd>=0.14.4\n",
            "  Downloading pyzstd-0.15.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (378 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m379.0/379.0 KB\u001b[0m \u001b[31m35.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pyppmd<1.1.0,>=0.18.1\n",
            "  Downloading pyppmd-1.0.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (139 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.7/139.7 KB\u001b[0m \u001b[31m18.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting multivolumefile>=0.2.3\n",
            "  Downloading multivolumefile-0.2.3-py3-none-any.whl (17 kB)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.8/dist-packages (from pytorch-transformers>=1.1.0->dadmatools) (2022.6.2)\n",
            "Collecting boto3\n",
            "  Downloading boto3-1.26.67-py3-none-any.whl (132 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.7/132.7 KB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sacremoses\n",
            "  Downloading sacremoses-0.0.53.tar.gz (880 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m880.6/880.6 KB\u001b[0m \u001b[31m63.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.8/dist-packages (from spacy>=3.0.0->dadmatools) (1.0.9)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from spacy>=3.0.0->dadmatools) (1.0.4)\n",
            "Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.8/dist-packages (from spacy>=3.0.0->dadmatools) (0.10.1)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /usr/local/lib/python3.8/dist-packages (from spacy>=3.0.0->dadmatools) (1.10.4)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.8/dist-packages (from spacy>=3.0.0->dadmatools) (3.3.0)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.8/dist-packages (from spacy>=3.0.0->dadmatools) (2.4.5)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.10 in /usr/local/lib/python3.8/dist-packages (from spacy>=3.0.0->dadmatools) (3.0.12)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from spacy>=3.0.0->dadmatools) (23.0)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from spacy>=3.0.0->dadmatools) (2.0.7)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in /usr/local/lib/python3.8/dist-packages (from spacy>=3.0.0->dadmatools) (0.10.1)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.8/dist-packages (from spacy>=3.0.0->dadmatools) (2.0.8)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.0 in /usr/local/lib/python3.8/dist-packages (from spacy>=3.0.0->dadmatools) (8.1.7)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from spacy>=3.0.0->dadmatools) (57.4.0)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from spacy>=3.0.0->dadmatools) (3.0.8)\n",
            "Requirement already satisfied: typer<0.8.0,>=0.3.0 in /usr/local/lib/python3.8/dist-packages (from spacy>=3.0.0->dadmatools) (0.7.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch>=1.7.1->dadmatools) (4.4.0)\n",
            "Collecting huggingface-hub<1.0,>=0.11.0\n",
            "  Downloading huggingface_hub-0.12.0-py3-none-any.whl (190 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m190.3/190.3 KB\u001b[0m \u001b[31m20.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
            "  Downloading tokenizers-0.13.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m113.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers>=4.9.1->dadmatools) (6.0)\n",
            "Collecting progressbar\n",
            "  Downloading progressbar-2.5.tar.gz (10 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (from NERDA->dadmatools) (1.3.5)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.8/dist-packages (from nltk->dadmatools) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.8/dist-packages (from nltk->dadmatools) (1.2.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.8/dist-packages (from jinja2>=2.9->folium>=0.2.1->dadmatools) (2.0.1)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->bpemb>=0.3.3->dadmatools) (4.0.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->bpemb>=0.3.3->dadmatools) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->bpemb>=0.3.3->dadmatools) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->bpemb>=0.3.3->dadmatools) (1.24.3)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.8/dist-packages (from thinc<8.2.0,>=8.1.0->spacy>=3.0.0->dadmatools) (0.7.9)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.8/dist-packages (from thinc<8.2.0,>=8.1.0->spacy>=3.0.0->dadmatools) (0.0.4)\n",
            "Collecting botocore<1.30.0,>=1.29.67\n",
            "  Downloading botocore-1.29.67-py3-none-any.whl (10.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.4/10.4 MB\u001b[0m \u001b[31m117.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting jmespath<2.0.0,>=0.7.1\n",
            "  Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Collecting s3transfer<0.7.0,>=0.6.0\n",
            "  Downloading s3transfer-0.6.0-py3-none-any.whl (79 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.6/79.6 KB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas->NERDA->dadmatools) (2022.7.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas->NERDA->dadmatools) (2.8.2)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.8/dist-packages (from requests->bpemb>=0.3.3->dadmatools) (1.7.1)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.8/dist-packages (from stanza->supar==1.1.2->dadmatools) (3.19.6)\n",
            "Collecting emoji\n",
            "  Downloading emoji-2.2.0.tar.gz (240 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m240.9/240.9 KB\u001b[0m \u001b[31m25.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting urllib3<1.27,>=1.21.1\n",
            "  Downloading urllib3-1.26.14-py2.py3-none-any.whl (140 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m140.6/140.6 KB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: sklearn, progressbar, sacremoses, emoji\n",
            "  Building wheel for sklearn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sklearn: filename=sklearn-0.0.post1-py3-none-any.whl size=2344 sha256=788ec219e24785ce00039919fd0b6afa4060695ff4606b4c397083e4ec662583\n",
            "  Stored in directory: /root/.cache/pip/wheels/14/25/f7/1cc0956978ae479e75140219088deb7a36f60459df242b1a72\n",
            "  Building wheel for progressbar (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for progressbar: filename=progressbar-2.5-py3-none-any.whl size=12081 sha256=d22291a45824acb84d1f63afe4ab8a18c62b4c2e4c4b0265bd2fd951f8eeb60c\n",
            "  Stored in directory: /root/.cache/pip/wheels/2c/67/ed/d84123843c937d7e7f5ba88a270d11036473144143355e2747\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.53-py3-none-any.whl size=895260 sha256=72d4dc9d34970cf51d93be1e5491f4b3ef6362e05abba7e0fd239881e9e76d01\n",
            "  Stored in directory: /root/.cache/pip/wheels/82/ab/9b/c15899bf659ba74f623ac776e861cf2eb8608c1825ddec66a4\n",
            "  Building wheel for emoji (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for emoji: filename=emoji-2.2.0-py3-none-any.whl size=234926 sha256=ff11ad4083c833a8e514c2951dd8f128a89bcd6b9f32f12c2f094da6e750a7b8\n",
            "  Stored in directory: /root/.cache/pip/wheels/86/62/9e/a6b27a681abcde69970dbc0326ff51955f3beac72f15696984\n",
            "Successfully built sklearn progressbar sacremoses emoji\n",
            "Installing collected packages: tokenizers, tf-estimator-nightly, texttable, sklearn, sentencepiece, py4j, progressbar, brotli, urllib3, segtok, sacremoses, pyzstd, pyppmd, pycryptodomex, pyconll, pybcj, multivolumefile, jmespath, inflate64, html2text, h5py, emoji, Deprecated, conllu, py7zr, hyperopt, botocore, stanza, s3transfer, huggingface-hub, bpemb, transformers, boto3, supar, pytorch-transformers, NERDA, dadmatools\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "  Attempting uninstall: h5py\n",
            "    Found existing installation: h5py 3.1.0\n",
            "    Uninstalling h5py-3.1.0:\n",
            "      Successfully uninstalled h5py-3.1.0\n",
            "  Attempting uninstall: hyperopt\n",
            "    Found existing installation: hyperopt 0.1.2\n",
            "    Uninstalling hyperopt-0.1.2:\n",
            "      Successfully uninstalled hyperopt-0.1.2\n",
            "Successfully installed Deprecated-1.2.6 NERDA-1.0.0 boto3-1.26.67 botocore-1.29.67 bpemb-0.3.4 brotli-1.0.9 conllu-4.5.2 dadmatools-1.5.2 emoji-2.2.0 h5py-3.8.0 html2text-2020.1.16 huggingface-hub-0.12.0 hyperopt-0.2.7 inflate64-0.3.1 jmespath-1.0.1 multivolumefile-0.2.3 progressbar-2.5 py4j-0.10.9.7 py7zr-0.20.2 pybcj-1.0.1 pyconll-3.1.0 pycryptodomex-3.17 pyppmd-1.0.0 pytorch-transformers-1.2.0 pyzstd-0.15.3 s3transfer-0.6.0 sacremoses-0.0.53 segtok-1.5.11 sentencepiece-0.1.97 sklearn-0.0.post1 stanza-1.4.2 supar-1.1.2 texttable-1.6.7 tf-estimator-nightly-2.8.0.dev2021122109 tokenizers-0.13.2 transformers-4.26.0 urllib3-1.26.14\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "urllib3"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import dadmatools"
      ],
      "metadata": {
        "id": "ubUfHzoe3qaW"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install fasttext\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "7J29yRfQlUaA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6bf37e33-39da-4ec2-f7f4-1d6408c55918"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting fasttext\n",
            "  Downloading fasttext-0.9.2.tar.gz (68 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m68.8/68.8 KB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pybind11>=2.2\n",
            "  Using cached pybind11-2.10.3-py3-none-any.whl (222 kB)\n",
            "Requirement already satisfied: setuptools>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from fasttext) (57.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from fasttext) (1.21.6)\n",
            "Building wheels for collected packages: fasttext\n",
            "  Building wheel for fasttext (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fasttext: filename=fasttext-0.9.2-cp38-cp38-linux_x86_64.whl size=4396344 sha256=ccd83952ba6d4556b2d707acb6c05ac25b0e5f7bb1cc919f2bc1687fa3a0667c\n",
            "  Stored in directory: /root/.cache/pip/wheels/93/61/2a/c54711a91c418ba06ba195b1d78ff24fcaad8592f2a694ac94\n",
            "Successfully built fasttext\n",
            "Installing collected packages: pybind11, fasttext\n",
            "Successfully installed fasttext-0.9.2 pybind11-2.10.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install utility"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ZbH_GS7o2zR",
        "outputId": "2191ad8f-48a9-41e6-b636-14407674d28d"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting utility\n",
            "  Downloading utility-1.0.tar.gz (3.1 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: utility\n",
            "  Building wheel for utility (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for utility: filename=utility-1.0-py3-none-any.whl size=3833 sha256=3e3dcd70027b9d2aa82ac83bc8b81c6ed4a66cc404cb596f85c95afb813df6f7\n",
            "  Stored in directory: /root/.cache/pip/wheels/01/88/f4/d0334bff483f781913d511756d750e37a1dc44e79e38893d41\n",
            "Successfully built utility\n",
            "Installing collected packages: utility\n",
            "Successfully installed utility-1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv(\"/content/Test_file.txt\", engine='python',encoding='utf-8', error_bad_lines=False)\n",
        "\n",
        "df.columns = [\"cat\", \"first\", \"second\", \"third\",\"fourth\"]\n",
        "\n",
        "print(\"The size of the analogy test set is : {}\".format(len(df)))\n",
        "print(df.head())\n",
        "\n"
      ],
      "metadata": {
        "id": "H8tf1YwbpBWm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "580b49d0-78d7-44ee-e6e3-57970fd13d49"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The size of the analogy test set is : 129\n",
            "    cat     first   second      third   fourth\n",
            "0  city     اهواز  خوزستان        قشم  هرمزگان\n",
            "1  city     شیراز     فارس     دامغان    سمنان\n",
            "2  city       رشت    گیلان  اسلام‌شهر    تهران\n",
            "3  city  بندرعباس  هرمزگان      ملارد    تهران\n",
            "4  city      اراک    مرکزی     مریوان  کردستان\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/IPython/core/interactiveshell.py:3326: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version.\n",
            "\n",
            "\n",
            "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "GloVe"
      ],
      "metadata": {
        "id": "MTxzQC64RA0a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import dadmatools\n",
        "from dadmatools.embeddings import get_embedding, get_all_embeddings_info, get_embedding_info\n",
        "embedding_info = get_embedding_info('glove-wiki')\n",
        "glove_embedding = get_embedding('glove-wiki')\n",
        "vocab = glove_embedding.get_vocab()\n"
      ],
      "metadata": {
        "id": "3VcAiqo5kapZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "115904dc-f6dd-4be6-f394-d6bfabb7af0d"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "vectors.zip: 100%|██████████| 45.9M/45.9M [00:00<00:00, 84.2MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "def find_cosine_similarity(vector1, vector2):\n",
        "    dot = np.dot(vector1,vector2)\n",
        "    norm1 = np.sqrt(np.sum(vector1**2))\n",
        "    norm2 = np.sqrt(np.sum(vector2**2))\n",
        "    cosine_sim = dot/(norm1)/norm2\n",
        "    \n",
        "    return cosine_sim"
      ],
      "metadata": {
        "id": "GbhB2wh_meLg"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def find_word_analogy(a, b, c, embedding):\n",
        "    # Get the word embeddings\n",
        "    emb_a, emb_b, emb_c = glove_embedding[a], glove_embedding[b], glove_embedding[c]\n",
        "    \n",
        "    # Get the nearest 100000 words to word_c\n",
        "    nearest = glove_embedding.top_nearest(c, 100)\n",
        "    word_list = [word[0] for word in nearest]\n",
        "    max_similarity = -100000\n",
        "    chosen_word = None\n",
        "\n",
        "    # Search for word_d in the word vector set\n",
        "    for word in word_list:\n",
        "        # Skip input words\n",
        "        if word in [a, b, c]:\n",
        "            continue\n",
        "\n",
        "        # Compute cosine similarity between vectors\n",
        "        sim = find_cosine_similarity(emb_b - emb_a, glove_embedding[word] - emb_c)\n",
        "        \n",
        "        # Update chosen word if similarity is higher\n",
        "        if sim > max_similarity:\n",
        "            max_similarity = sim\n",
        "            chosen_word = word\n",
        "\n",
        "    return chosen_word    "
      ],
      "metadata": {
        "id": "tlRBlFzTsuXX"
      },
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "Wc06LXAyULID",
        "outputId": "24f19d05-00e4-4ed4-da1a-4dd33c0113e5"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "             cat     first   second      third    fourth\n",
              "0           city     اهواز  خوزستان        قشم   هرمزگان\n",
              "1           city     شیراز     فارس     دامغان     سمنان\n",
              "2           city       رشت    گیلان  اسلام‌شهر     تهران\n",
              "3           city  بندرعباس  هرمزگان      ملارد     تهران\n",
              "4           city      اراک    مرکزی     مریوان   کردستان\n",
              "..           ...       ...      ...        ...       ...\n",
              "124  gram_plural     مسافر  مسافرین        طلا     طلاها\n",
              "125  gram_plural      مجرم   مجرمین       شورا    شوراها\n",
              "126  gram_plural     انسان  انسانها      پرنده   پرندگان\n",
              "127  gram_plural       ارز    ارزها     بیگانه  بیگانگان\n",
              "128  gram_plural       طلا    طلاها       مورد     موارد\n",
              "\n",
              "[129 rows x 5 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d366b004-6a97-4dc2-bd61-6380df786e59\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>cat</th>\n",
              "      <th>first</th>\n",
              "      <th>second</th>\n",
              "      <th>third</th>\n",
              "      <th>fourth</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>city</td>\n",
              "      <td>اهواز</td>\n",
              "      <td>خوزستان</td>\n",
              "      <td>قشم</td>\n",
              "      <td>هرمزگان</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>city</td>\n",
              "      <td>شیراز</td>\n",
              "      <td>فارس</td>\n",
              "      <td>دامغان</td>\n",
              "      <td>سمنان</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>city</td>\n",
              "      <td>رشت</td>\n",
              "      <td>گیلان</td>\n",
              "      <td>اسلام‌شهر</td>\n",
              "      <td>تهران</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>city</td>\n",
              "      <td>بندرعباس</td>\n",
              "      <td>هرمزگان</td>\n",
              "      <td>ملارد</td>\n",
              "      <td>تهران</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>city</td>\n",
              "      <td>اراک</td>\n",
              "      <td>مرکزی</td>\n",
              "      <td>مریوان</td>\n",
              "      <td>کردستان</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>124</th>\n",
              "      <td>gram_plural</td>\n",
              "      <td>مسافر</td>\n",
              "      <td>مسافرین</td>\n",
              "      <td>طلا</td>\n",
              "      <td>طلاها</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>125</th>\n",
              "      <td>gram_plural</td>\n",
              "      <td>مجرم</td>\n",
              "      <td>مجرمین</td>\n",
              "      <td>شورا</td>\n",
              "      <td>شوراها</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>126</th>\n",
              "      <td>gram_plural</td>\n",
              "      <td>انسان</td>\n",
              "      <td>انسانها</td>\n",
              "      <td>پرنده</td>\n",
              "      <td>پرندگان</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>127</th>\n",
              "      <td>gram_plural</td>\n",
              "      <td>ارز</td>\n",
              "      <td>ارزها</td>\n",
              "      <td>بیگانه</td>\n",
              "      <td>بیگانگان</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>128</th>\n",
              "      <td>gram_plural</td>\n",
              "      <td>طلا</td>\n",
              "      <td>طلاها</td>\n",
              "      <td>مورد</td>\n",
              "      <td>موارد</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>129 rows × 5 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d366b004-6a97-4dc2-bd61-6380df786e59')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d366b004-6a97-4dc2-bd61-6380df786e59 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d366b004-6a97-4dc2-bd61-6380df786e59');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "glove accuracy"
      ],
      "metadata": {
        "id": "-ZalI-5g45kF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y= df[df[\"cat\"]==\"city\"]\n",
        "first = y[\"first\"]\n",
        "second = y[\"second\"]\n",
        "third = y[\"third\"]\n",
        "fourth = y[\"fourth\"]\n",
        "accuracy = 0\n",
        "for i in range (9):\n",
        "    print(i)\n",
        "    inputs = [(first[i], second[i], third[i])]\n",
        "    for input in inputs:\n",
        "        word4 = find_word_analogy(*input, glove_embedding)\n",
        "        print (input)\n",
        "        print (word4)\n",
        "        if (word4==fourth[i]):\n",
        "            accuracy = accuracy + 1\n",
        "            \n",
        "num = y[\"cat\"].count()      \n",
        "print(accuracy/num)      \n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mPj3l_9SU2TM",
        "outputId": "b051740f-d16a-4cf4-ad3f-ce31d8191a88"
      },
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "('اهواز', 'خوزستان', 'قشم')\n",
            "هرمزگان\n",
            "1\n",
            "('شیراز', 'فارس', 'دامغان')\n",
            "لرستان\n",
            "2\n",
            "('رشت', 'گیلان', 'اسلام\\u200cشهر')\n",
            "آل‌قاورد\n",
            "3\n",
            "('بندرعباس', 'هرمزگان', 'ملارد')\n",
            "ماهورمیلانی\n",
            "4\n",
            "('اراک', 'مرکزی', 'مریوان')\n",
            "بخش\n",
            "5\n",
            "('اسلام\\u200cشهر', 'تهران', 'جهرم')\n",
            "شیراز\n",
            "6\n",
            "('سنندج', 'کردستان', 'آبادان')\n",
            "خوزستان\n",
            "7\n",
            "('گرگان', 'گلستان', 'قشم')\n",
            "دهلران\n",
            "8\n",
            "('ملارد', 'تهران', 'جهرم')\n",
            "شیراز\n",
            "0.2222222222222222\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y= df[df[\"cat\"]==\"capital\"]\n",
        "first = y[\"first\"]\n",
        "second = y[\"second\"]\n",
        "third = y[\"third\"]\n",
        "fourth = y[\"fourth\"]\n",
        "accuracy = 0\n",
        "for i in range (9,19):\n",
        "    print(i)\n",
        "    inputs = [(first[i], second[i], third[i])]\n",
        "    for input in inputs:\n",
        "        word4 = find_word_analogy(*input, glove_embedding)\n",
        "        print (input)\n",
        "        print (word4)\n",
        "        if (word4==fourth[i]):\n",
        "            accuracy = accuracy + 1\n",
        "            \n",
        "num = y[\"cat\"].count()      \n",
        "print(accuracy/num)      \n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bc244e74-68f4-4295-a6c5-45bb84953fa1",
        "id": "c4eJZzoGYnYi"
      },
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9\n",
            "('روسیه', 'مسکو', 'هلند')\n",
            "آمستردام\n",
            "10\n",
            "('کره\\u200cجنوبی', 'سئول', 'آمریکا')\n",
            "لندن\n",
            "11\n",
            "('ایران', 'تهران', 'اسپانیا')\n",
            "استانبول\n",
            "12\n",
            "('ایران', 'تهران', 'افغانستان')\n",
            "اشرف\n",
            "13\n",
            "('بریتانیا', 'لندن', 'فنلاند')\n",
            "آمستردام\n",
            "14\n",
            "('تایلند', 'بانکوک', 'چین')\n",
            "پکن\n",
            "15\n",
            "('مصر', 'قاهره', 'چین')\n",
            "پکن\n",
            "16\n",
            "('اندونزی', 'جاکارتا', 'اتریش')\n",
            "بوداپست\n",
            "17\n",
            "('عراق', 'بغداد', 'بلغارستان')\n",
            "تفلیس\n",
            "18\n",
            "('آلمان', 'برلین', 'اسپانیا')\n",
            "ونیز\n",
            "0.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y= df[df[\"cat\"]==\"currency\"]\n",
        "first = y[\"first\"]\n",
        "second = y[\"second\"]\n",
        "third = y[\"third\"]\n",
        "fourth = y[\"fourth\"]\n",
        "accuracy = 0\n",
        "for i in range (19,28):\n",
        "    print(i)\n",
        "    inputs = [(first[i], second[i], third[i])]\n",
        "    for input in inputs:\n",
        "        word4 = find_word_analogy(*input, glove_embedding)\n",
        "        print (input)\n",
        "        print (word4)\n",
        "        if (word4==fourth[i]):\n",
        "            accuracy = accuracy + 1\n",
        "            \n",
        "num = y[\"cat\"].count()      \n",
        "print(accuracy/num)      \n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jths3p-RYqds",
        "outputId": "f139c246-6455-4c75-b86e-e8e4f85e1619"
      },
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "19\n",
            "('سوئد', 'کرون', 'امارات')\n",
            "دایموند\n",
            "20\n",
            "('سوئیس', 'فرانک', 'تاجیکستان')\n",
            "عبدالناصر\n",
            "21\n",
            "('رومانی', 'لئو', 'بریتانیا')\n",
            "دیوید\n",
            "22\n",
            "('ترکیه', 'لیره', 'افغانستان')\n",
            "دالر\n",
            "23\n",
            "('چین', 'یوان', 'عراق')\n",
            "هنیه\n",
            "24\n",
            "('اروپا', 'یورو', 'ایران')\n",
            "تومان\n",
            "25\n",
            "('اروپا', 'یورو', 'هند')\n",
            "روپیه\n",
            "26\n",
            "('ژاپن', 'ین', 'اروپا')\n",
            "الف\n",
            "27\n",
            "('سوئیس', 'فرانک', 'کنیا')\n",
            "کلایو\n",
            "0.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y= df[df[\"cat\"]==\"family\"]\n",
        "first = y[\"first\"]\n",
        "second = y[\"second\"]\n",
        "third = y[\"third\"]\n",
        "fourth = y[\"fourth\"]\n",
        "accuracy = 0\n",
        "for i in range (29,37):\n",
        "    print(i)\n",
        "    inputs = [(first[i], second[i], third[i])]\n",
        "\n",
        "    for input in inputs:\n",
        "        if(input[0] in vocab and input[1] in vocab and input[2] in vocab):\n",
        "            word4 = find_word_analogy(*input, glove_embedding)\n",
        "            print (input)\n",
        "            print (word4)\n",
        "            if (word4==fourth[i]):\n",
        "                accuracy = accuracy + 1\n",
        "            \n",
        "num = y[\"cat\"].count()      \n",
        "print(accuracy/num)      \n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xgcgUafBYqj9",
        "outputId": "49fa4849-7d9d-4a82-9bf0-54460b341a17"
      },
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "29\n",
            "('برادر', 'خواهر', 'پدر')\n",
            "مادر\n",
            "30\n",
            "('برادرها', 'خواهرها', 'شوهر')\n",
            "سایدر\n",
            "31\n",
            "('پدربزرگ', 'مادربزرگ', 'برادر')\n",
            "رستوران\n",
            "32\n",
            "33\n",
            "('داماد', 'عروس', 'برادرها')\n",
            "غرق\n",
            "34\n",
            "('شوهر', 'عیال', 'دایی')\n",
            "طارق\n",
            "35\n",
            "('شاه', 'ملکه', 'برادر')\n",
            "خواهر\n",
            "36\n",
            "('آقا', 'خانم', 'آقاجون')\n",
            "گوهرشادبیگم\n",
            "0.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y= df[df[\"cat\"]==\"gram_thirdperson\"]\n",
        "first = y[\"first\"]\n",
        "second = y[\"second\"]\n",
        "third = y[\"third\"]\n",
        "fourth = y[\"fourth\"]\n",
        "accuracy = 0\n",
        "for i in range (39,49):\n",
        "    print(i)\n",
        "    inputs = [(first[i], second[i], third[i])]\n",
        "\n",
        "    for input in inputs:\n",
        "        if(input[0] in vocab and input[1] in vocab and input[2] in vocab):\n",
        "            word4 = find_word_analogy(*input, glove_embedding)\n",
        "            print (input)\n",
        "            print (word4)\n",
        "            if (word4==fourth[i]):\n",
        "                accuracy = accuracy + 1\n",
        "             \n",
        "num = y[\"cat\"].count()      \n",
        "print(accuracy/num)      \n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1mX0b1ULYq4M",
        "outputId": "77a1cbb0-c329-4930-cf6c-19dea2b641cd"
      },
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "39\n",
            "('برید', 'بریدند', 'رقصید')\n",
            "گیلدنسترن\n",
            "40\n",
            "('پرید', 'پریدند', 'آمد')\n",
            "پرآب\n",
            "41\n",
            "42\n",
            "('شد', 'شدند', 'بوسید')\n",
            "ارزش‌هایشان\n",
            "43\n",
            "('کرد', 'کردند', 'آمد')\n",
            "آمدند\n",
            "44\n",
            "('گفت', 'گفتند', 'رقصید')\n",
            "sunny\n",
            "45\n",
            "('توانست', 'توانستند', 'یافت')\n",
            "ساکنان\n",
            "46\n",
            "47\n",
            "('رسید', 'رسیدند', 'شد')\n",
            "شدند\n",
            "48\n",
            "('خواست', 'خواستند', 'آمد')\n",
            "آمدند\n",
            "0.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y= df[df[\"cat\"]==\"gram_past\"]\n",
        "first = y[\"first\"]\n",
        "second = y[\"second\"]\n",
        "third = y[\"third\"]\n",
        "fourth = y[\"fourth\"]\n",
        "accuracy = 0\n",
        "for i in range (49,59):\n",
        "    print(i)\n",
        "    inputs = [(first[i], second[i], third[i])]\n",
        "\n",
        "    for input in inputs:\n",
        "        if(input[0] in vocab and input[1] in vocab and input[2] in vocab):\n",
        "            word4 = find_word_analogy(*input, glove_embedding)\n",
        "            print (input)\n",
        "            print (word4)\n",
        "            if (word4==fourth[i]):\n",
        "                accuracy = accuracy + 1\n",
        "             \n",
        "num = y[\"cat\"].count()   \n",
        "print(accuracy/num)   "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y-RhFSqQYq88",
        "outputId": "6a70017a-cdc8-4ed2-86af-76a7bf8b7b62"
      },
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "49\n",
            "('بریدن', 'برید', 'دمیدن')\n",
            "نالی\n",
            "50\n",
            "51\n",
            "('شدن', 'شد', 'نگریستن')\n",
            "راند\n",
            "52\n",
            "('گفتن', 'گفت', 'رقصیدن')\n",
            "فعالیت\n",
            "53\n",
            "('گفتن', 'گفت', 'خواستن')\n",
            "ملت\n",
            "54\n",
            "('توانستن', 'توانست', 'رسیدن')\n",
            "رسید\n",
            "55\n",
            "('رفتن', 'رفت', 'زدن')\n",
            "شد\n",
            "56\n",
            "('رفتن', 'رفت', 'افزودن')\n",
            "رساند\n",
            "57\n",
            "('گرفتن', 'گرفت', 'توانستن')\n",
            "بنی‌مجیدی\n",
            "58\n",
            "('خواستن', 'خواست', 'فرمودن')\n",
            "کنسرتهایی\n",
            "0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y= df[df[\"cat\"]==\"gram_firstperson\"]\n",
        "first = y[\"first\"]\n",
        "second = y[\"second\"]\n",
        "third = y[\"third\"]\n",
        "fourth = y[\"fourth\"]\n",
        "accuracy = 0\n",
        "for i in range (59,69):\n",
        "    print(i)\n",
        "    inputs = [(first[i], second[i], third[i])]\n",
        "\n",
        "    for input in inputs:\n",
        "        if(input[0] in vocab and input[1] in vocab and input[2] in vocab):\n",
        "            word4 = find_word_analogy(*input, glove_embedding)\n",
        "            print (input)\n",
        "            print (word4)\n",
        "            if (word4==fourth[i]):\n",
        "                accuracy = accuracy + 1\n",
        "             \n",
        "num = y[\"cat\"].count()   \n",
        "print(accuracy/num)     \n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "si3GEyXhYrCV",
        "outputId": "0899d738-1ea5-43a7-b35b-d947e1bf84a8"
      },
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "59\n",
            "('دادم', 'دادیم', 'یافتم')\n",
            "می‌فریبد\n",
            "60\n",
            "('زدم', 'زدیم', 'نامیدم')\n",
            "می‌خرم\n",
            "61\n",
            "('نوشتم', 'نوشتیم', 'گفتم')\n",
            "هرجا\n",
            "62\n",
            "63\n",
            "64\n",
            "65\n",
            "('گذاشتم', 'گذاشتیم', 'کردم')\n",
            "کارش\n",
            "66\n",
            "('گذاشتم', 'گذاشتیم', 'ماندم')\n",
            "ستامپر\n",
            "67\n",
            "68\n",
            "0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y= df[df[\"cat\"]==\"gram_adj2adv\"]\n",
        "first = y[\"first\"]\n",
        "second = y[\"second\"]\n",
        "third = y[\"third\"]\n",
        "fourth = y[\"fourth\"]\n",
        "accuracy = 0\n",
        "for i in range (69,79):\n",
        "    print(i)\n",
        "    inputs = [(first[i], second[i], third[i])]\n",
        "\n",
        "    for input in inputs:\n",
        "        if(input[0] in vocab and input[1] in vocab and input[2] in vocab):\n",
        "            word4 = find_word_analogy(*input, glove_embedding)\n",
        "            print (input)\n",
        "            print (word4)\n",
        "            if (word4==fourth[i]):\n",
        "                accuracy = accuracy + 1\n",
        "             \n",
        "num = y[\"cat\"].count()   \n",
        "print(accuracy/num)     \n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DP08up8nYrHJ",
        "outputId": "395902e4-5c4b-4555-83ca-b5fb7e87b2b9"
      },
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "69\n",
            "('مجدد', 'مجددا', 'مخصوص')\n",
            "می‌شد\n",
            "70\n",
            "('عمده', 'عمدتا', 'صمیمی')\n",
            "داغشو\n",
            "71\n",
            "('دقیق', 'دقیقا', 'عادل')\n",
            "اکرم\n",
            "72\n",
            "('غالب', 'غالبا', 'جدا')\n",
            "داخل\n",
            "73\n",
            "('متناظر', 'متناظرا', 'قبل')\n",
            "اواخر\n",
            "74\n",
            "('متاسف', 'متاسفانه', 'قبل')\n",
            "این\n",
            "75\n",
            "('خوشبخت', 'خوشبختانه', 'مجدد')\n",
            "گسترش\n",
            "76\n",
            "('صمیمی', 'صمیمانه', 'صادق')\n",
            "خامنه‌ای\n",
            "77\n",
            "('آزاد', 'آزادانه', 'متاسف')\n",
            "علاقه‌مندم\n",
            "78\n",
            "('آگاه', 'آگاهانه', 'سرسخت')\n",
            "برتری‌های\n",
            "0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y= df[df[\"cat\"]==\"gram_noun2adv\"]\n",
        "first = y[\"first\"]\n",
        "second = y[\"second\"]\n",
        "third = y[\"third\"]\n",
        "fourth = y[\"fourth\"]\n",
        "accuracy = 0\n",
        "for i in range (79,89):\n",
        "    print(i)\n",
        "    inputs = [(first[i], second[i], third[i])]\n",
        "\n",
        "    for input in inputs:\n",
        "        if(input[0] in vocab and input[1] in vocab and input[2] in vocab):\n",
        "            word4 = find_word_analogy(*input, glove_embedding)\n",
        "            print (input)\n",
        "            print (word4)\n",
        "            if (word4==fourth[i]):\n",
        "                accuracy = accuracy + 1\n",
        "             \n",
        "num = y[\"cat\"].count()   \n",
        "print(accuracy/num)     \n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-9C_mEhvYrR8",
        "outputId": "37e39a63-0bfd-4e13-c442-abb819c1bd9c"
      },
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "79\n",
            "('اتفاق', 'اتفاقا', 'شب')\n",
            "شبی\n",
            "80\n",
            "('حتم', 'حتما', 'اساس')\n",
            "بر\n",
            "81\n",
            "('اصل', 'اصلا', 'انسان')\n",
            "نمی‌تواند\n",
            "82\n",
            "('عمل', 'عملا', 'اجبار')\n",
            "ناگزیر\n",
            "83\n",
            "('اجبار', 'اجبارا', 'کودک')\n",
            "خلاق\n",
            "84\n",
            "('دائم', 'دائما', 'اتفاق')\n",
            "اتفاقات\n",
            "85\n",
            "('طبع', 'طبعا', 'سوم')\n",
            "پیشین\n",
            "86\n",
            "('نسبت', 'نسبتا', 'اصل')\n",
            "اساسا\n",
            "87\n",
            "('اصول', 'اصولا', 'دوم')\n",
            "پادشاه\n",
            "88\n",
            "('اساس', 'اساسا', 'نسبت')\n",
            "تمایل\n",
            "0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y= df[df[\"cat\"]==\"gram_antonym\"]\n",
        "first = y[\"first\"]\n",
        "second = y[\"second\"]\n",
        "third = y[\"third\"]\n",
        "fourth = y[\"fourth\"]\n",
        "accuracy = 0\n",
        "for i in range (89,99):\n",
        "    print(i)\n",
        "    inputs = [(first[i], second[i], third[i])]\n",
        "\n",
        "    for input in inputs:\n",
        "        if(input[0] in vocab and input[1] in vocab and input[2] in vocab):\n",
        "            word4 = find_word_analogy(*input, glove_embedding)\n",
        "            print (input)\n",
        "            print (word4)\n",
        "            if (word4==fourth[i]):\n",
        "                accuracy = accuracy + 1\n",
        "             \n",
        "num = y[\"cat\"].count()   \n",
        "print(accuracy/num)     "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_il1Y_gUYrXj",
        "outputId": "48d9f0ba-52a1-4912-bca5-2765dfe05310"
      },
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "89\n",
            "('خشنود', 'ناخشنود', 'موفق')\n",
            "رقابت\n",
            "90\n",
            "('درست', 'نادرست', 'پخته')\n",
            "نسوز\n",
            "91\n",
            "('مناسب', 'نامناسب', 'همزمان')\n",
            "بلافاصله\n",
            "92\n",
            "('مربوط', 'نامربوط', 'منسجم')\n",
            "صورت‌بندی\n",
            "93\n",
            "('بینا', 'نابینا', 'درست')\n",
            "تصور\n",
            "94\n",
            "('کارآمد', 'ناکارآمد', 'هنجار')\n",
            "اجلال\n",
            "95\n",
            "('راضی', 'ناراضی', 'مطلوب')\n",
            "نامطلوب\n",
            "96\n",
            "('مطلوب', 'نامطلوب', 'مناسب')\n",
            "نامناسب\n",
            "97\n",
            "('پیدا', 'ناپیدا', 'متعارف')\n",
            "توزیعی\n",
            "98\n",
            "('مساعد', 'نامساعد', 'درست')\n",
            "ممکن\n",
            "0.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y= df[df[\"cat\"]==\"gram_comparative\"]\n",
        "first = y[\"first\"]\n",
        "second = y[\"second\"]\n",
        "third = y[\"third\"]\n",
        "fourth = y[\"fourth\"]\n",
        "accuracy = 0\n",
        "for i in range (99,109):\n",
        "    print(i)\n",
        "    inputs = [(first[i], second[i], third[i])]\n",
        "\n",
        "    for input in inputs:\n",
        "        if(input[0] in vocab and input[1] in vocab and input[2] in vocab):\n",
        "            word4 = find_word_analogy(*input, glove_embedding)\n",
        "            print (input)\n",
        "            print (word4)\n",
        "            if (word4==fourth[i]):\n",
        "                accuracy = accuracy + 1\n",
        "             \n",
        "num = y[\"cat\"].count()   \n",
        "print(accuracy/num)    "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kdcy-L64Yrc-",
        "outputId": "abd668fa-8365-46c8-fda6-01664f6c8552"
      },
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "99\n",
            "('سریع', 'سریعتر', 'بلند')\n",
            "بلندتر\n",
            "100\n",
            "('بزرگ', 'بزرگتر', 'شدید')\n",
            "شدیدتر\n",
            "101\n",
            "('مهم', 'مهمتر', 'بارز')\n",
            "مشخص‌ترین\n",
            "102\n",
            "('به', 'بهتر', 'سرد')\n",
            "تابستانهای\n",
            "103\n",
            "('واضح', 'واضحتر', 'بیش')\n",
            "یکصد\n",
            "104\n",
            "('کم', 'کمتر', 'بد')\n",
            "چگونه\n",
            "105\n",
            "('بالا', 'بالاتر', 'به')\n",
            "کرده‌است\n",
            "106\n",
            "('معروف', 'معروفتر', 'مشهور')\n",
            "غیرمتحرکند\n",
            "107\n",
            "('بلند', 'بلندتر', 'نزدیک')\n",
            "مکانطول\n",
            "108\n",
            "('بد', 'بدتر', 'مهم')\n",
            "دلایل\n",
            "0.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y= df[df[\"cat\"]==\"gram_nationality\"]\n",
        "first = y[\"first\"]\n",
        "second = y[\"second\"]\n",
        "third = y[\"third\"]\n",
        "fourth = y[\"fourth\"]\n",
        "accuracy = 0\n",
        "for i in range (109,118):\n",
        "    print(i)\n",
        "    inputs = [(first[i], second[i], third[i])]\n",
        "\n",
        "    for input in inputs:\n",
        "        if(input[0] in vocab and input[1] in vocab and input[2] in vocab):\n",
        "            word4 = find_word_analogy(*input, glove_embedding)\n",
        "            print (input)\n",
        "            print (word4)\n",
        "            if (word4==fourth[i]):\n",
        "                accuracy = accuracy + 1\n",
        "             \n",
        "num = y[\"cat\"].count()   \n",
        "print(accuracy/num)    "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hbteZqBcim2m",
        "outputId": "083ca46a-1ea5-47ae-903a-4e24564fd2db"
      },
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "109\n",
            "('اتریش', 'اتریشی', 'اسپانیا')\n",
            "ایتالیایی\n",
            "110\n",
            "('سوئد', 'سوئدی', 'فنلاند')\n",
            "اوهاکئا\n",
            "111\n",
            "('بحرین', 'بحرینی', 'عراق')\n",
            "عراقی\n",
            "112\n",
            "('کویت', 'کویتی', 'سوریه')\n",
            "نظامیان\n",
            "113\n",
            "('مصر', 'مصری', 'کرواسی')\n",
            "زمپلن\n",
            "114\n",
            "('مصر', 'مصری', 'فرانسه')\n",
            "فرانسوی\n",
            "115\n",
            "('برزیل', 'برزیلی', 'آمریکا')\n",
            "آمریکایی\n",
            "116\n",
            "('برزیل', 'برزیلی', 'انگلستان')\n",
            "کمنیتسر\n",
            "117\n",
            "('روسیه', 'روسی', 'یونان')\n",
            "یونانی\n",
            "0.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y= df[df[\"cat\"]==\"gram_plural\"]\n",
        "first = y[\"first\"]\n",
        "second = y[\"second\"]\n",
        "third = y[\"third\"]\n",
        "fourth = y[\"fourth\"]\n",
        "accuracy = 0\n",
        "for i in range (119,128):\n",
        "    print(i)\n",
        "    inputs = [(first[i], second[i], third[i])]\n",
        "\n",
        "    for input in inputs:\n",
        "        if(input[0] in vocab and input[1] in vocab and input[2] in vocab):\n",
        "            word4 = find_word_analogy(*input, glove_embedding)\n",
        "            print (input)\n",
        "            print (word4)\n",
        "            if (word4==fourth[i]):\n",
        "                accuracy = accuracy + 1\n",
        "             \n",
        "num = y[\"cat\"].count()   \n",
        "print(accuracy/num)    "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3QCVzHlmituW",
        "outputId": "31b78c8d-8691-445f-d613-d380bfc136dd"
      },
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "119\n",
            "('تالیف', 'تالیفات', 'مخلوق')\n",
            "قویترین\n",
            "120\n",
            "('اثر', 'اثرات', 'ارزش')\n",
            "ناخالص\n",
            "121\n",
            "('انقلابی', 'انقلابیون', 'مورد')\n",
            "گرفتن\n",
            "122\n",
            "('حواری', 'حواریون', 'مورد')\n",
            "خود\n",
            "123\n",
            "('مسئول', 'مسئولین', 'آزاده')\n",
            "بوزی\n",
            "124\n",
            "('مسافر', 'مسافرین', 'طلا')\n",
            "مسکوکات\n",
            "125\n",
            "('مجرم', 'مجرمین', 'شورا')\n",
            "مشورتی\n",
            "126\n",
            "('انسان', 'انسانها', 'پرنده')\n",
            "پرنده‌های\n",
            "127\n",
            "('ارز', 'ارزها', 'بیگانه')\n",
            "سرکش\n",
            "0.0\n"
          ]
        }
      ]
    }
  ]
}